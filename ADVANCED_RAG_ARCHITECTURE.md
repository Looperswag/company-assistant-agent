# 高级RAG架构设计方案

## 概述

本文档描述了一个基于现有架构的进阶RAG（检索增强生成）系统，旨在显著提升知识库召回精度和整体系统性能。

## 当前架构分析

### 现有架构优点
- 模块化设计清晰
- 支持语义检索（向量搜索）
- 具备基础的多轮对话能力
- 安全过滤机制完善

### 现有架构局限性
1. **单一检索策略**：仅依赖向量语义检索，缺乏关键词匹配
2. **无重排序机制**：检索结果直接使用，未经过精细化排序
3. **查询扩展不足**：无法处理用户查询表达不准确的情况
4. **固定检索参数**：无法根据查询复杂度动态调整
5. **上下文利用率低**：检索结果直接拼接，未做优化压缩

## 高级RAG架构设计

### 架构分层图

```
┌─────────────────────────────────────────────────────────────┐
│                     用户查询层                                │
└────────────────────┬────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────┐
│              查询预处理与扩展层                               │
│  - 查询标准化                                               │
│  - 查询扩展（同义词、相关概念）                               │
│  - 查询意图识别                                              │
└────────────────────┬────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────┐
│              自适应检索策略层                                 │
│  - 混合检索策略选择                                          │
│  - 动态参数调整                                              │
└──────┬───────────────────────┬──────────────────────────────┘
       ↓                       ↓
┌──────────────────┐   ┌──────────────────┐
│   语义向量检索    │   │   关键词检索(BM25) │
│  (Sentence-      │   │  (本地实现)        │
│   Transformers)   │   │                   │
└────────┬─────────┘   └────────┬──────────┘
         ↓                       ↓
         └───────────┬───────────┘
                     ↓
┌─────────────────────────────────────────────────────────────┐
│              结果融合与去重层                                 │
│  - Reciprocal Rank Fusion (RRF)                              │
│  - 结果去重                                                  │
└────────────────────┬────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────┐
│              交叉编码器重排序层                                │
│  - 使用BGE-Reranker或Cohere Rerank                          │
│  - 重新计算相关性分数                                         │
└────────────────────┬────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────┐
│              上下文优化层                                     │
│  - LongLLMLingua压缩                                         │
│  - 动态上下文长度控制                                         │
│  - 相关性过滤                                                │
└────────────────────┬────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────┐
│              LLM生成层                                        │
│  - 带有优化后上下文的提示词构建                                │
│  - 多轮对话上下文管理                                         │
└────────────────────┬────────────────────────────────────────┘
                     ↓
┌─────────────────────────────────────────────────────────────┐
│              响应输出层                                        │
│  - 引用来源标注                                              │
│  - 置信度显示                                                │
└─────────────────────────────────────────────────────────────┘
```

## 核心技术模块详解

### 1. 查询预处理与扩展

#### 1.1 查询标准化
```python
def normalize_query(query: str) -> str:
    """
    查询标准化处理：
    - 去除多余空格
    - 统一标点符号
    - 繁简转换（如需要）
    - 大小写统一
    """
```

#### 1.2 查询扩展策略
**方法1：同义词扩展**
- 使用词库或语言模型生成同义词
- 例如："请假" → "休假、休年假、调休、事假"

**方法2：相关概念扩展**
- 基于知识图谱或WordNet
- 例如："编码规范" → "代码风格、编程标准、开发规范"

**方法3：多查询生成**
- 使用LLM生成多个相关查询
- 合并多个查询的检索结果

### 2. 混合检索（Hybrid Search）

#### 2.1 向量检索（已有优化）
- 使用更强大的中文embedding模型
- 推荐模型：`bge-large-zh-v1.5` 或 `m3e-large`

#### 2.2 BM25关键词检索
- 实现本地BM25算法
- 适用于精确匹配、专有名词、代码片段
- 与向量检索形成互补

#### 2.3 检索结果融合算法
**Reciprocal Rank Fusion (RRF)**
```python
def reciprocal_rank_fusion(results_list: List[List[dict]], k: int = 60) -> List[dict]:
    """
    RRF融合算法
    - k: 常数参数，通常60
    - 对每个文档计算综合分数
    """
    scores = {}
    for results in results_list:
        for rank, doc in enumerate(results):
            doc_id = doc['id']
            if doc_id not in scores:
                scores[doc_id] = 0
            scores[doc_id] += 1 / (k + rank + 1)
    
    # 按分数排序
    sorted_results = sorted(scores.items(), key=lambda x: x[1], reverse=True)
    return sorted_results
```

### 3. 交叉编码器重排序

#### 3.1 为什么需要重排序
- 向量检索速度快但精度有限
- 交叉编码器精度高但速度慢
- 先粗检再精排，平衡速度和精度

#### 3.2 推荐重排序模型

**选项1：BGE-Reranker（开源免费）**
- 模型：`BAAI/bge-reranker-v2-m3`
- 优势：中文优化、开源免费、可本地部署
- 使用方式：
```python
from FlagEmbedding import FlagReranker
reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True)
scores = reranker.compute_score([query, passage])
```

**选项2：Cohere Rerank API（有免费额度）**
- API端点：https://api.cohere.ai/v1/rerank
- 免费额度：每月1000次调用
- 优势：云服务、无需部署、持续优化

### 4. 上下文优化

#### 4.1 LongLLMLingua压缩
- 移除上下文中的无关信息
- 保留最相关的内容
- 提高token利用率

#### 4.2 动态上下文长度
- 根据查询复杂度调整上下文长度
- 简单查询：使用较少上下文
- 复杂查询：使用更多上下文

#### 4.3 分层上下文
```python
def build_layered_context(results: List[dict], query: str) -> str:
    """
    构建分层上下文
    - 第一层：最相关的文档块
    - 第二层：次相关的文档块
    - 每层添加相关性分数
    """
```

### 5. 自适应检索策略

#### 5.1 查询复杂度评估
- 查询长度
- 是否包含多个问题
- 是否需要推理

#### 5.2 动态参数调整
```python
class AdaptiveRetrievalStrategy:
    def get_params(self, query: str) -> dict:
        complexity = self.assess_complexity(query)
        return {
            'n_results': 10 if complexity > 0.7 else 5,
            'similarity_threshold': 0.6 if complexity > 0.7 else 0.7,
            'use_expansion': complexity > 0.5,
            'use_reranking': True,
        }
```

## 实施路线图

### 阶段1：基础设施升级（优先级：高）
1. **升级Embedding模型**
   - 替换为`bge-large-zh-v1.5`
   - 重新索引知识库
   - 预期提升：10-15%

2. **实现BM25检索**
   - 添加本地BM25实现
   - 集成到现有检索流程
   - 预期提升：5-10%

### 阶段2：混合检索与重排序（优先级：高）
1. **实现RRF融合**
   - 合并向量和BM25结果
   - 调优融合参数
   - 预期提升：10-15%

2. **集成重排序模型**
   - 部署BGE-Reranker
   - 或使用Cohere Rerank API
   - 预期提升：15-20%

### 阶段3：查询优化（优先级：中）
1. **查询扩展**
   - 实现同义词扩展
   - 集成多查询生成
   - 预期提升：5-10%

2. **查询标准化**
   - 实现查询预处理
   - 提高检索一致性

### 阶段4：上下文优化（优先级：中）
1. **上下文压缩**
   - 集成LongLLMLingua
   - 优化上下文长度
   - 预期提升：5-8%

2. **自适应策略**
   - 实现查询复杂度评估
   - 动态参数调整

### 阶段5：增强功能（优先级：低）
1. **引用来源标注**
   - 显示答案来源文档
   - 提供可点击链接

2. **置信度显示**
   - 计算回答置信度
   - 向用户展示可靠性

## 性能预期

### 召回率提升
- 当前：约60-70%
- 阶段1后：约70-75%
- 阶段2后：约80-85%
- 全部实施后：约85-90%

### 精确率提升
- 当前：约65-75%
- 阶段1后：约75-80%
- 阶段2后：约85-90%
- 全部实施后：约90-95%

### 响应时间影响
- 阶段1：+10-20%（模型更大）
- 阶段2：+30-40%（重排序）
- 阶段3：+10-15%（查询扩展）
- 阶段4：-10-15%（上下文压缩优化）
- **总计：+40-50%**（可接受范围）

## 免费API推荐方案

### 知识库相关

#### 1. 向量数据库（已使用）
- **ChromaDB**（免费）
  - 优势：本地部署、开源、易用
  - 当前已使用

- **Qdrant**（免费）
  - 优势：高性能、支持云端和本地
  - 云端免费：1GB存储
  - 适用场景：需要云端部署

#### 2. Embedding模型

**选项1：本地开源模型（推荐）**
- **bge-large-zh-v1.5**（推荐）
  - 下载：`https://huggingface.co/BAAI/bge-large-zh-v1.5`
  - 优势：中文优化、性能优秀、完全免费
  - 部署：本地运行，无需API

- **m3e-large**
  - 下载：`https://huggingface.co/moka-ai/m3e-large`
  - 优势：中文通用、轻量级

**选项2：API服务**

- **Jina Embeddings**（有免费额度）
  - 端点：`https://api.jina.ai/v1/embeddings`
  - 免费额度：每月100万tokens
  - 申请：https://jina.ai/

- **Cohere Embed**（有免费额度）
  - 端点：`https://api.cohere.ai/v1/embed`
  - 免费额度：每月100次调用
  - 申请：https://cohere.com/

#### 3. 重排序模型

**选项1：本地开源模型（推荐）**
- **BGE-Reranker-v2-m3**（推荐）
  - 下载：`https://huggingface.co/BAAI/bge-reranker-v2-m3`
  - 安装：`pip install -U FlagEmbedding`
  - 代码：
  ```python
  from FlagEmbedding import FlagReranker
  reranker = FlagReranker('BAAI/bge-reranker-v2-m3', use_fp16=True)
  ```

- **bge-reranker-large**
  - 下载：`https://huggingface.co/BAAI/bge-reranker-large`
  - 优势：更高精度，但更慢

**选项2：API服务**

- **Cohere Rerank**（有免费额度）
  - 端点：`https://api.cohere.ai/v1/rerank`
  - 免费额度：每月1000次调用
  - 申请：https://cohere.com/

### 网络检索相关

#### 1. 搜索API（已使用）
- **DuckDuckGo**（免费）
  - 优势：完全免费、无API密钥
  - 当前已使用
  - 局限性：结果质量一般

#### 2. 其他免费搜索API

**选项1：SerpAPI**（有免费额度）
- 端点：`https://serpapi.com/search`
- 免费额度：每月100次搜索
- 优势：支持Google、Bing等
- 申请：https://serpapi.com/

**选项2：Google Custom Search API**（有免费额度）
- 端点：`https://www.googleapis.com/customsearch/v1`
- 免费额度：每天100次查询
- 优势：Google搜索质量
- 申请：https://developers.google.com/custom-search

**选项3：Tavily API**（有免费额度）
- 端点：`https://api.tavily.com/search`
- 免费额度：每月1000次查询
- 优势：AI优化搜索
- 申请：https://tavily.com/

#### 3. 网页内容提取

**选项1：Jina Reader**（免费）
- 端点：`https://r.jina.ai/http://example.com`
- 优势：完全免费、提取干净内容
- 使用示例：
```python
import requests
url = "https://r.jina.ai/http://example.com"
response = requests.get(url)
content = response.text
```

**选项2：Readability.js**（开源）
- 本地实现，无需API
- 使用Mozilla的Readability库
- 安装：`pip install readability-lxml`

### 辅助工具

#### 1. 查询扩展
- **Ollama**（本地免费）
  - 运行本地LLM进行查询扩展
  - 安装：https://ollama.com/
  - 模型：`qwen2.5:7b` 或 `gemma2:9b`

#### 2. 文档处理
- **Unstructured**（开源免费）
  - 解析PDF、Word、PPT等
  - 安装：`pip install unstructured`
  - 支持多种格式

#### 3. 中文分词（用于BM25）
- **jieba**（开源免费）
  - 安装：`pip install jieba`
  - 用于BM25的中文分词

## 推荐技术栈组合

### 方案A：完全免费本地部署（推荐）
```
向量数据库: ChromaDB（本地）
Embedding: bge-large-zh-v1.5（本地）
重排序: BGE-Reranker-v2-m3（本地）
搜索: DuckDuckGo（免费API）
文档解析: Unstructured（本地）
```

**优势**：
- 完全免费，无API费用
- 数据隐私，全部本地
- 无网络依赖（除搜索外）

**劣势**：
- 需要一定的硬件资源
- 模型需要首次下载

### 方案B：混合方案（平衡性能和成本）
```
向量数据库: ChromaDB（本地）
Embedding: bge-large-zh-v1.5（本地）
重排序: Cohere Rerank（API，免费额度）
搜索: Tavily API（免费额度）
文档解析: Unstructured（本地）
```

**优势**：
- 核心功能本地化
- 利用云端API优化
- 成本可控

**劣势**：
- 需要管理多个API密钥
- 有网络依赖

### 方案C：云端优先（便于部署）
```
向量数据库: Qdrant Cloud（免费1GB）
Embedding: Jina Embeddings（免费额度）
重排序: Cohere Rerank（免费额度）
搜索: Tavily API（免费额度）
文档解析: Unstructured（本地）
```

**优势**：
- 易于部署和扩展
- 无需维护本地模型
- 性能可能更好

**劣势**：
- 数据上传云端
- 免费额度限制
- 有网络依赖

## 成本对比（月度）

| 项目 | 方案A | 方案B | 方案C |
|------|-------|-------|-------|
| 向量数据库 | $0 | $0 | $0（1GB） |
| Embedding | $0 | $0 | $0（100万tokens） |
| 重排序 | $0 | $0（1000次） | $0（1000次） |
| 搜索 | $0 | $0（1000次） | $0（1000次） |
| 文档解析 | $0 | $0 | $0 |
| **总计** | **$0** | **$0** | **$0** |

> 注：所有方案在免费额度内完全免费。超出额度后会产生费用。

## 实施建议

### 立即实施（第1-2周）
1. 升级Embedding模型到`bge-large-zh-v1.5`
2. 实现本地BM25检索
3. 集成BGE-Reranker-v2-m3

### 短期实施（第3-4周）
1. 实现RRF融合算法
2. 实现查询扩展（同义词）
3. 优化上下文构建

### 中期实施（第5-8周）
1. 集成LongLLMLingua压缩
2. 实现自适应检索策略
3. 添加引用来源标注

### 长期优化（持续）
1. 收集用户反馈
2. 持续优化参数
3. 评估新模型和技术

## 监控与评估指标

### 技术指标
- **召回率（Recall）**：检索到相关文档的比例
- **精确率（Precision）**：检索结果中相关文档的比例
- **MRR（Mean Reciprocal Rank）**：第一个相关结果的排名
- **NDCG（Normalized Discounted Cumulative Gain）**：排序质量

### 业务指标
- **回答准确率**：用户反馈的准确率
- **解决率**：用户问题被解决的比例
- **满意度**：用户满意度评分
- **平均响应时间**：端到端响应时间

## 总结

本高级RAG架构方案通过以下关键技术显著提升知识库召回精度：

1. **混合检索**：向量检索 + BM25，互补优势
2. **重排序机制**：交叉编码器精细排序
3. **查询扩展**：提升查询表达能力
4. **上下文优化**：提高token利用率
5. **自适应策略**：动态调整检索参数

预计整体召回率可从60-70%提升至85-90%，精确率可从65-75%提升至90-95%。

推荐采用**方案A（完全免费本地部署）**，在保证性能的同时实现零成本运行。
